
# Herunterladen von HTML-Seiten

In den folgenden Aufgaben laden wir Daten von einer statischen Webseite oder einem RSS-Feed herunter.

### Aufgabe 1

Suche Dir eine der folgenden Seiten aus:

#### RSS-Feeds des Parlaments

* `https://www.parlament-berlin.de/de/Service/RSS-Feeds`

#### Biologische Datenbanken

* `http://ncbi.nlm.nih.gov`

#### Presse

* `http://www.reuters.com/tools/rss`

#### Demographie

* `http://www.gapminder.org`

#### Bücher

* `http://www.gutenberg.org`


### Aufgabe 2

Zeige den Quelltext der Seite/des Feeds an. Versuche, markante Elemente zu finden, anhand derer Du den Titel, Links oder Inhalte erkennst.

### Aufgabe 3

Extrahiere den Titel der Seite aus dem HTML-Dokument/Feed und gib ihn auf dem Bildschirm aus. Verwende dazu die normalen Stringfunktionen.

### Aufgabe 4

Extrahiere Links oder andere Daten aus der Seite. Entwickle dazu eine Strategie, die entweder die Methoden von Strings, reguläre Ausdrücke oder einen fertigen Parser verwendet.

### Aufgabe 5

Lade 10 der verlinkten Seiten herunter und speichere sie ab.


## Nützliche Module

* `requests` zum Herunterladen von Webseiten
* `BeautifulSoup` zum Parsen von HTML-Seiten
* `scrapy` für beides zusammen

